{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c25dff8e-c9dc-4f85-95c5-88ff3698a382",
      "metadata": {
        "id": "c25dff8e-c9dc-4f85-95c5-88ff3698a382"
      },
      "source": [
        "# PaddleOCR Fine-tune steps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddleocr\n",
        "!pip install paddlepaddle-gpu\n",
        "!python3 -m pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoPPDSDG12qM",
        "outputId": "4d334a71-b55a-46ea-ef1b-64d9db876340"
      },
      "id": "KoPPDSDG12qM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddleocr\n",
            "  Downloading paddleocr-2.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.25.2)\n",
            "Collecting pyclipper (from paddleocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting lmdb (from paddleocr)\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.0.2)\n",
            "Collecting rapidfuzz (from paddleocr)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from paddleocr) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddleocr) (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from paddleocr) (6.0.2)\n",
            "Collecting python-docx (from paddleocr)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.13.3)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.57.0)\n",
            "Collecting fire>=0.3.0 (from paddleocr)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.32.3)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.0.5)\n",
            "Requirement already satisfied: albucore in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.0.23)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.3.0->paddleocr) (3.0.1)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore->paddleocr) (3.12.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore->paddleocr) (6.2.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albucore->paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations->paddleocr) (1.14.1)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->paddleocr) (2.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->paddleocr) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->paddleocr) (4.13.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx->paddleocr) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (2025.1.31)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (0.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->paddleocr) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->paddleocr) (0.4.0)\n",
            "Downloading paddleocr-2.10.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=bb5e53630d299b88c64074ff48cc521f27884d801ba3c216a9eb698ff8754ff2\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: pyclipper, lmdb, rapidfuzz, python-docx, fire, paddleocr\n",
            "Successfully installed fire-0.7.0 lmdb-1.6.2 paddleocr-2.10.0 pyclipper-1.3.0.post6 python-docx-1.1.2 rapidfuzz-3.13.0\n",
            "Collecting paddlepaddle-gpu\n",
            "  Downloading paddlepaddle_gpu-2.6.2-cp311-cp311-manylinux1_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu) (11.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu) (4.4.2)\n",
            "Collecting astor (from paddlepaddle-gpu)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting opt-einsum==3.3.0 (from paddlepaddle-gpu)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu) (5.29.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->paddlepaddle-gpu) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle-gpu) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle-gpu) (4.13.1)\n",
            "Downloading paddlepaddle_gpu-2.6.2-cp311-cp311-manylinux1_x86_64.whl (759.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.0/759.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Installing collected packages: opt-einsum, astor, paddlepaddle-gpu\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "Successfully installed astor-0.8.1 opt-einsum-3.3.0 paddlepaddle-gpu-2.6.2\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test that paddle detects gpu running\n",
        "import paddle\n",
        "print(paddle.device.get_device())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Hlf4s_3j-y",
        "outputId": "8cd29738-362f-40e9-9be3-d13b88f82cec"
      },
      "id": "T6Hlf4s_3j-y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/paddle/base/framework.py:688: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f33916d4-d860-4749-9b9a-17030e25fd2c",
      "metadata": {
        "id": "f33916d4-d860-4749-9b9a-17030e25fd2c"
      },
      "source": [
        "## Make sure to run `train_data/data_preprocess.ipynb` BEFORE running these commands on terminal!\n",
        "## Don't run these commands in jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clear previus info if its there\n",
        "#%rm -rf train_data/\n",
        "#%rm -rf pretrain_models/\n",
        "#%rm -rf PaddleOCR/\n",
        "#%rm -rf trainingImages/"
      ],
      "metadata": {
        "id": "gpVoF9-Zw2RG"
      },
      "id": "gpVoF9-Zw2RG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get folder with images from repo\n",
        "#%rm -rf train_data\n",
        "!git clone https://github.com/scruz10FAU/trainingImages.git\n",
        "#move the images needed to main directory\n",
        "%mv trainingImages/trainText .\n",
        "#rename folder to train_data for paddleOCR processing\n",
        "%mv trainText train_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0di7TP0telo",
        "outputId": "ccaa09dc-5f91-47ad-e425-aca3a11e1261"
      },
      "id": "r0di7TP0telo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trainingImages'...\n",
            "remote: Enumerating objects: 3453, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 3453 (delta 2), reused 8 (delta 2), pack-reused 3442 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3453/3453), 263.65 MiB | 22.67 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Move best_accuracy to main folder for later use\n",
        "#%mv trainingImages/best_accuracy/ .git"
      ],
      "metadata": {
        "id": "JA3GqzpwxL6P"
      },
      "id": "JA3GqzpwxL6P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove git repo\n",
        "!rm -rf trainingImages\n",
        "#great groundtruth.csv\n",
        "#%cp train_data/full_list.txt train_data/groundtruth.txt\n",
        "!sed 's/ \\+/,/g' train_data/full_list.txt > train_data/groundtruth.csv"
      ],
      "metadata": {
        "id": "Yu6gIiS2wslm"
      },
      "id": "Yu6gIiS2wslm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def label_reader(file_path):\n",
        "    true_labels = {}\n",
        "\n",
        "    with open(file_path) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        #print(csv_reader)\n",
        "        for row in csv_reader:\n",
        "          try:\n",
        "            #print(f\"ROW: {row}\")\n",
        "            true_labels[row[0]] = row[1]\n",
        "          except:\n",
        "            pass\n",
        "            #print(f\"ERROR: {row}\")\n",
        "\n",
        "    return true_labels\n",
        "\n",
        "true_labels = label_reader('train_data/groundtruth.csv')\n",
        "len(true_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4jjnYn2tjRa",
        "outputId": "c1c89f82-d92e-4cb0-db4c-80f9b6be7063"
      },
      "id": "V4jjnYn2tjRa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%pwd\n",
        "#%rm -rf train_data/train_list.txt\n",
        "#%rm -rf train_data/val_list.txt\n",
        "#%rm -rf train_data/val\n",
        "#%rm -rf train_data/train"
      ],
      "metadata": {
        "id": "41aCd9QW8ySL"
      },
      "id": "41aCd9QW8ySL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mpPB2ACu9IWJ"
      },
      "id": "mpPB2ACu9IWJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test datasets\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def split_data(data_dir, train_dir, val_dir, img_dir, label_dict, train_percent=0.8):\n",
        "  #create training and val directories\n",
        "  os.makedirs(train_dir, exist_ok=True)\n",
        "  os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "  #get all image files\n",
        "  image_files = os.listdir(img_dir)\n",
        "  image_files = [file for file in image_files if file in label_dict]\n",
        "  random.shuffle(image_files)\n",
        "\n",
        "  #Get the number of training files\n",
        "  num_train = int(len(image_files)* train_percent)\n",
        "  #get the list of training images from dataset\n",
        "  train_images = image_files[:num_train]\n",
        "  #get the list of val images from dataset\n",
        "  val_images = image_files[num_train:]\n",
        "\n",
        "  for file_name in train_images:\n",
        "    label_string =f\"train/{file_name} {label_dict[file_name]}\"\n",
        "    src_path = os.path.join(img_dir, file_name)\n",
        "    dst_path = os.path.join(train_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "    with open(os.path.join(data_dir, 'train_list.txt'), \"a\") as f:\n",
        "      f.write(f\"{label_string}\\n\")\n",
        "\n",
        "  for file_name in val_images:\n",
        "    label_string =f\"val/{file_name} {label_dict[file_name]}\"\n",
        "    src_path = os.path.join(img_dir, file_name)\n",
        "    dst_path = os.path.join(val_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "    with open(os.path.join(data_dir, 'val_list.txt'), \"a\") as f:\n",
        "      f.write(f\"{label_string}\\n\")\n",
        "\n",
        "split_data(\"train_data\", \"train_data/train\", \"train_data/val\", \"train_data/images\", true_labels)"
      ],
      "metadata": {
        "id": "Zgws9DPxt0c0"
      },
      "id": "Zgws9DPxt0c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a29381fe-51a8-4118-8607-2e943ea965ad",
      "metadata": {
        "id": "a29381fe-51a8-4118-8607-2e943ea965ad"
      },
      "source": [
        "## In the current project 1 directory, clone PaddleOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7968adab-4074-455e-998a-07b03f0dad31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7968adab-4074-455e-998a-07b03f0dad31",
        "outputId": "6747b6e6-a909-43e8-bb93-fc6d6249b55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PaddleOCR'...\n",
            "remote: Enumerating objects: 138306, done.\u001b[K\n",
            "remote: Counting objects: 100% (8675/8675), done.\u001b[K\n",
            "remote: Compressing objects: 100% (939/939), done.\u001b[K\n",
            "remote: Total 138306 (delta 8388), reused 7736 (delta 7736), pack-reused 129631 (from 4)\u001b[K\n",
            "Receiving objects: 100% (138306/138306), 819.36 MiB | 26.83 MiB/s, done.\n",
            "Resolving deltas: 100% (108008/108008), done.\n",
            "Updating files: 100% (2028/2028), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a18ba5-fee7-44f8-909c-975ef1fb14f3",
      "metadata": {
        "id": "98a18ba5-fee7-44f8-909c-975ef1fb14f3"
      },
      "source": [
        "## Move train data and `accuracy_evaluate.ipynb` to main repository\n",
        "\n",
        "From now on, run `accuracy_evaluate.ipynb` under the `PaddleOCR` directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove training data if it existed already\n",
        "#%pwd\n",
        "#%rm -rf PaddleOCR/train_data\n"
      ],
      "metadata": {
        "id": "FiNvxlJu9eVD"
      },
      "id": "FiNvxlJu9eVD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757df76b-432d-4d8a-b4a4-db9b35135a02",
      "metadata": {
        "id": "757df76b-432d-4d8a-b4a4-db9b35135a02"
      },
      "outputs": [],
      "source": [
        "!cp -r train_data PaddleOCR/train_data\n",
        "#!cp accuracy_evaluate.ipynb PaddleOCR/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eccd534-4122-4417-bbe4-2c551e9870eb",
      "metadata": {
        "id": "0eccd534-4122-4417-bbe4-2c551e9870eb"
      },
      "source": [
        "## cd to PaddleOCR directory and download pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13984ea6-360d-45d9-8cd8-d3f5491c25dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13984ea6-360d-45d9-8cd8-d3f5491c25dd",
        "outputId": "9db61be4-dafd-481a-e16b-7e1d9a1712c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PaddleOCR\n"
          ]
        }
      ],
      "source": [
        "%cd PaddleOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef788e5-3dac-404e-8d6f-afed99022757",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ef788e5-3dac-404e-8d6f-afed99022757",
        "outputId": "34b6c029-035e-4c13-c675-001567cfdf59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-11 02:51:34--  https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar\n",
            "Resolving paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)... 103.235.47.176, 2402:2b40:7000:628:0:ff:b0e8:88da\n",
            "Connecting to paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)|103.235.47.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204093440 (195M) [application/x-tar]\n",
            "Saving to: ‘./pretrain_models/en_PP-OCRv3_rec_train.tar’\n",
            "\n",
            "en_PP-OCRv3_rec_tra 100%[===================>] 194.64M  16.7MB/s    in 29s     \n",
            "\n",
            "2025-04-11 02:52:05 (6.75 MB/s) - ‘./pretrain_models/en_PP-OCRv3_rec_train.tar’ saved [204093440/204093440]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf1be93-e94b-41f3-b163-ea6d9612a543",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf1be93-e94b-41f3-b163-ea6d9612a543",
        "outputId": "d985385c-d3db-4230-e4aa-34c24eab36d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PaddleOCR/pretrain_models\n"
          ]
        }
      ],
      "source": [
        "%cd pretrain_models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkApEG_Iv8lc",
        "outputId": "e8c82ff0-1129-4b9c-b0b5-479709462dbe"
      },
      "id": "NkApEG_Iv8lc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PaddleOCR/pretrain_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bcfd3d-e45e-4a56-a593-e9782bb2e1ec",
      "metadata": {
        "id": "f8bcfd3d-e45e-4a56-a593-e9782bb2e1ec"
      },
      "outputs": [],
      "source": [
        "!tar -xf en_PP-OCRv3_rec_train.tar && rm -rf en_PP-OCRv3_rec_train.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PaddleOCR/pretrain_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcJ5Ovc8ytdQ",
        "outputId": "ff08ff71-d5c2-4bfb-a96c-8ef858f0e6f6"
      },
      "id": "qcJ5Ovc8ytdQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'PaddleOCR/pretrain_models'\n",
            "/content/PaddleOCR/pretrain_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Move old model and replace with new best accuracy contents\n",
        "!mv en_PP-OCRv3_rec_train en_PP-OCRv3_rec_train_old\n",
        "!mkdir en_PP-OCRv3_rec_train\n",
        "\n",
        "%cd ../../\n",
        "!pwd\n",
        "\n",
        "!mv best_accuracy.pdopt PaddleOCR/pretrain_models/en_PP-OCRv3_rec_train/\n",
        "!mv best_accuracy.pdparams PaddleOCR/pretrain_models/en_PP-OCRv3_rec_train/\n",
        "!mv best_accuracy.states PaddloeOCR/pretrain_models/en_PP-OCRv3_rec_train/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV9IAGz1yJ6j",
        "outputId": "880700f8-d096-4446-a5f1-8b43714a27af"
      },
      "id": "wV9IAGz1yJ6j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n",
            "mv: cannot move 'best_accuracy.states' to 'PaddloeOCR/pretrain_models/en_PP-OCRv3_rec_train/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Move best accuracy contents to appropriate folder\n",
        "#!mv best_accuracy/en_PP-OCRv3_rec_train/en_PP-OCRv3_rec_train/* en_PP-OCRv3_rec_train/"
      ],
      "metadata": {
        "id": "B3excfJdypTs"
      },
      "id": "B3excfJdypTs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d9ac70d4-997f-45e9-8bd5-dc27935c8441",
      "metadata": {
        "id": "d9ac70d4-997f-45e9-8bd5-dc27935c8441"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "%cd content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ_13AI1957h",
        "outputId": "4b485464-9fe1-4bda-aa46-e58a9be471e5"
      },
      "id": "AZ_13AI1957h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9655c4b-9216-42b8-a8e5-2fd80a918c1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9655c4b-9216-42b8-a8e5-2fd80a918c1b",
        "outputId": "3456efd0-f96c-430a-e3e9-a19610c87d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PaddleOCR\n"
          ]
        }
      ],
      "source": [
        "# cd back to PaddleOCR main directory\n",
        "%cd PaddleOCR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qyO3pKbS79yR",
        "outputId": "a7be2d49-d702-4952-bebc-a50cd4614a43"
      },
      "id": "qyO3pKbS79yR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/PaddleOCR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up train_list.txt to avoid formatting issues\n",
        "cleaned_lines = []\n",
        "with open('./train_data/train_list.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line == '':\n",
        "            continue  # skip empty lines\n",
        "        parts = line.split()\n",
        "        #print(f\"{parts[0]}\\t{parts[1]}\")\n",
        "        if len(parts) >= 2:\n",
        "            cleaned_lines.append(f\"{parts[0]}\\t{parts[1]}\")\n",
        "\n",
        "with open('./train_data/train_list.txt', 'w') as f:\n",
        "    f.write('\\n'.join(cleaned_lines))\n",
        "\n",
        "print(\"train_list.txt cleaned!\")\n",
        "\n",
        "# Clean up train_list.txt to avoid formatting issues\n",
        "cleaned_lines = []\n",
        "with open('./train_data/val_list.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line == '':\n",
        "            continue  # skip empty lines\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 2:\n",
        "            cleaned_lines.append(f\"{parts[0]}\\t{parts[1]}\")\n",
        "\n",
        "with open('./train_data/val_list.txt', 'w') as f:\n",
        "    f.write('\\n'.join(cleaned_lines))\n",
        "\n",
        "print(\"val_list.txt cleaned!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LCMawti-218",
        "outputId": "0cf393e9-9079-4f85-81da-b4de9732751d"
      },
      "id": "1LCMawti-218",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_list.txt cleaned!\n",
            "val_list.txt cleaned!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V_mJjNaoBC-k",
        "outputId": "1e80c57d-6208-4bfb-a99c-e1c3f3e9031a"
      },
      "id": "V_mJjNaoBC-k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/PaddleOCR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "bad_images = []\n",
        "with open('./train_data/train_list.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip().split()[0]\n",
        "        try:\n",
        "            img = Image.open(os.path.join('./train_data', line))\n",
        "        except:\n",
        "            bad_images.append(line)\n",
        "\n",
        "print(bad_images if bad_images else \"No bad images found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LitmpNq3AnWk",
        "outputId": "58df0103-7c56-4edd-8973-c93d3d3893d8"
      },
      "id": "LitmpNq3AnWk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No bad images found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b96fb045-b6e9-41f0-9f39-c3c17e658546",
      "metadata": {
        "id": "b96fb045-b6e9-41f0-9f39-c3c17e658546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a131ef-aba9-4c61-cc0f-6160a7994521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/paddle/base/framework.py:688: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\n",
            "  warnings.warn(\n",
            "[2025/04/11 02:52:15] ppocr WARNING: Skipping import of the encryption module.\n",
            "[2025/04/11 02:52:16] ppocr INFO: Architecture : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     Backbone : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         last_conv_stride : [1, 2]\n",
            "[2025/04/11 02:52:16] ppocr INFO:         last_pool_kernel_size : [2, 2]\n",
            "[2025/04/11 02:52:16] ppocr INFO:         last_pool_type : avg\n",
            "[2025/04/11 02:52:16] ppocr INFO:         name : MobileNetV1Enhance\n",
            "[2025/04/11 02:52:16] ppocr INFO:         scale : 0.5\n",
            "[2025/04/11 02:52:16] ppocr INFO:     Head : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         head_list : \n",
            "[2025/04/11 02:52:16] ppocr INFO:             CTCHead : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 Head : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                     fc_decay : 1e-05\n",
            "[2025/04/11 02:52:16] ppocr INFO:                 Neck : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                     depth : 2\n",
            "[2025/04/11 02:52:16] ppocr INFO:                     dims : 64\n",
            "[2025/04/11 02:52:16] ppocr INFO:                     hidden_dims : 120\n",
            "[2025/04/11 02:52:16] ppocr INFO:                     name : svtr\n",
            "[2025/04/11 02:52:16] ppocr INFO:                     use_guide : True\n",
            "[2025/04/11 02:52:16] ppocr INFO:             SARHead : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 enc_dim : 512\n",
            "[2025/04/11 02:52:16] ppocr INFO:                 max_text_length : 25\n",
            "[2025/04/11 02:52:16] ppocr INFO:         name : MultiHead\n",
            "[2025/04/11 02:52:16] ppocr INFO:     Transform : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:     algorithm : SVTR_LCNet\n",
            "[2025/04/11 02:52:16] ppocr INFO:     model_type : rec\n",
            "[2025/04/11 02:52:16] ppocr INFO: Eval : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     dataset : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         data_dir : ./train_data\n",
            "[2025/04/11 02:52:16] ppocr INFO:         label_file_list : ['./train_data/val_list.txt']\n",
            "[2025/04/11 02:52:16] ppocr INFO:         name : SimpleDataSet\n",
            "[2025/04/11 02:52:16] ppocr INFO:         transforms : \n",
            "[2025/04/11 02:52:16] ppocr INFO:             DecodeImage : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 channel_first : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:                 img_mode : BGR\n",
            "[2025/04/11 02:52:16] ppocr INFO:             MultiLabelEncode : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:             RecResizeImg : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 image_shape : [3, 48, 320]\n",
            "[2025/04/11 02:52:16] ppocr INFO:             KeepKeys : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 keep_keys : ['image', 'label_ctc', 'label_sar', 'length', 'valid_ratio']\n",
            "[2025/04/11 02:52:16] ppocr INFO:     loader : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         batch_size_per_card : 25\n",
            "[2025/04/11 02:52:16] ppocr INFO:         drop_last : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:         num_workers : 4\n",
            "[2025/04/11 02:52:16] ppocr INFO:         shuffle : False\n",
            "[2025/04/11 02:52:16] ppocr INFO: Global : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     cal_metric_during_train : True\n",
            "[2025/04/11 02:52:16] ppocr INFO:     character_dict_path : ppocr/utils/en_dict.txt\n",
            "[2025/04/11 02:52:16] ppocr INFO:     checkpoints : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:     debug : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:     distributed : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:     epoch_num : 50\n",
            "[2025/04/11 02:52:16] ppocr INFO:     eval_batch_step : [0, 10]\n",
            "[2025/04/11 02:52:16] ppocr INFO:     infer_img : doc/imgs_words/ch/word_1.jpg\n",
            "[2025/04/11 02:52:16] ppocr INFO:     infer_mode : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:     log_smooth_window : 20\n",
            "[2025/04/11 02:52:16] ppocr INFO:     max_text_length : 25\n",
            "[2025/04/11 02:52:16] ppocr INFO:     pretrained_model : ./pretrain_models/en_PP-OCRv3_rec_train/best_accuracy\n",
            "[2025/04/11 02:52:16] ppocr INFO:     print_batch_step : 10\n",
            "[2025/04/11 02:52:16] ppocr INFO:     save_best_model : True\n",
            "[2025/04/11 02:52:16] ppocr INFO:     save_epoch_step : 3\n",
            "[2025/04/11 02:52:16] ppocr INFO:     save_inference_dir : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:     save_model_dir : ./output/v3_en_mobile\n",
            "[2025/04/11 02:52:16] ppocr INFO:     save_res_path : ./output/rec/predicts_ppocrv3_en.txt\n",
            "[2025/04/11 02:52:16] ppocr INFO:     use_gpu : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:     use_space_char : True\n",
            "[2025/04/11 02:52:16] ppocr INFO:     use_visualdl : False\n",
            "[2025/04/11 02:52:16] ppocr INFO: Loss : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     loss_config_list : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         CTCLoss : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:         SARLoss : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:     name : MultiLoss\n",
            "[2025/04/11 02:52:16] ppocr INFO: Metric : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     ignore_space : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:     main_indicator : acc\n",
            "[2025/04/11 02:52:16] ppocr INFO:     name : RecMetric\n",
            "[2025/04/11 02:52:16] ppocr INFO: Optimizer : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     beta1 : 0.9\n",
            "[2025/04/11 02:52:16] ppocr INFO:     beta2 : 0.999\n",
            "[2025/04/11 02:52:16] ppocr INFO:     lr : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         learning_rate : 0.001\n",
            "[2025/04/11 02:52:16] ppocr INFO:         name : Cosine\n",
            "[2025/04/11 02:52:16] ppocr INFO:         warmup_epoch : 5\n",
            "[2025/04/11 02:52:16] ppocr INFO:     name : Adam\n",
            "[2025/04/11 02:52:16] ppocr INFO:     regularizer : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         factor : 3e-05\n",
            "[2025/04/11 02:52:16] ppocr INFO:         name : L2\n",
            "[2025/04/11 02:52:16] ppocr INFO: PostProcess : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     name : CTCLabelDecode\n",
            "[2025/04/11 02:52:16] ppocr INFO: Train : \n",
            "[2025/04/11 02:52:16] ppocr INFO:     dataset : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         data_dir : ./train_data/\n",
            "[2025/04/11 02:52:16] ppocr INFO:         ext_op_transform_idx : 1\n",
            "[2025/04/11 02:52:16] ppocr INFO:         label_file_list : ['./train_data/train_list.txt']\n",
            "[2025/04/11 02:52:16] ppocr INFO:         name : SimpleDataSet\n",
            "[2025/04/11 02:52:16] ppocr INFO:         transforms : \n",
            "[2025/04/11 02:52:16] ppocr INFO:             DecodeImage : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 channel_first : False\n",
            "[2025/04/11 02:52:16] ppocr INFO:                 img_mode : BGR\n",
            "[2025/04/11 02:52:16] ppocr INFO:             RecConAug : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 ext_data_num : 2\n",
            "[2025/04/11 02:52:16] ppocr INFO:                 image_shape : [48, 320, 3]\n",
            "[2025/04/11 02:52:16] ppocr INFO:                 max_text_length : 25\n",
            "[2025/04/11 02:52:16] ppocr INFO:                 prob : 0.5\n",
            "[2025/04/11 02:52:16] ppocr INFO:             RecAug : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:             MultiLabelEncode : None\n",
            "[2025/04/11 02:52:16] ppocr INFO:             RecResizeImg : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 image_shape : [3, 48, 320]\n",
            "[2025/04/11 02:52:16] ppocr INFO:             KeepKeys : \n",
            "[2025/04/11 02:52:16] ppocr INFO:                 keep_keys : ['image', 'label_ctc', 'label_sar', 'length', 'valid_ratio']\n",
            "[2025/04/11 02:52:16] ppocr INFO:     loader : \n",
            "[2025/04/11 02:52:16] ppocr INFO:         batch_size_per_card : 25\n",
            "[2025/04/11 02:52:16] ppocr INFO:         drop_last : True\n",
            "[2025/04/11 02:52:16] ppocr INFO:         num_workers : 4\n",
            "[2025/04/11 02:52:16] ppocr INFO:         shuffle : True\n",
            "[2025/04/11 02:52:16] ppocr INFO: profiler_options : None\n",
            "[2025/04/11 02:52:16] ppocr INFO: train with paddle 2.6.2 and device Place(cpu)\n",
            "[2025/04/11 02:52:16] ppocr INFO: Initialize indexes of datasets:['./train_data/train_list.txt']\n",
            "[2025/04/11 02:52:16] ppocr INFO: Initialize indexes of datasets:['./train_data/val_list.txt']\n",
            "[2025/04/11 02:52:16] ppocr INFO: train dataloader has 5 iters\n",
            "[2025/04/11 02:52:16] ppocr INFO: valid dataloader has 2 iters\n",
            "[2025/04/11 02:52:17] ppocr INFO: load pretrain successful from ./pretrain_models/en_PP-OCRv3_rec_train/best_accuracy\n",
            "[2025/04/11 02:52:17] ppocr INFO: During the training process, after the 0th iteration, an evaluation is run every 10 iterations\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/PaddleOCR/tools/train.py\", line 272, in <module>\n",
            "    main(config, device, logger, vdl_writer, seed)\n",
            "  File \"/content/PaddleOCR/tools/train.py\", line 225, in main\n",
            "    program.train(\n",
            "  File \"/content/PaddleOCR/tools/program.py\", line 448, in train\n",
            "    max_mem_reserved_str = f\", max_mem_reserved: {paddle.device.cuda.max_memory_reserved() // (1024 ** 2)} MB,\"\n",
            "                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/paddle/device/cuda/__init__.py\", line 283, in max_memory_reserved\n",
            "    device_id = extract_cuda_device_id(device, op_name=name)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/paddle/device/cuda/__init__.py\", line 189, in extract_cuda_device_id\n",
            "    return core.get_cuda_current_device_id()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: (External) CUDA error(35), CUDA driver version is insufficient for CUDA runtime version. \n",
            "  [Hint: 'cudaErrorInsufficientDriver'. This indicates that the installed NVIDIA CUDA driver is older than the CUDA runtime library. This is not a supported configuration.Users should install an updated NVIDIA display driver to allow the application to run.] (at /paddle/paddle/phi/backends/gpu/cuda/cuda_info.cc:178)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 tools/train.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.pretrained_model=./pretrain_models/en_PP-OCRv3_rec_train/best_accuracy Train.loader.batch_size_per_card=25 Eval.loader.batch_size_per_card=25 Global.use_gpu=False Global.epoch_num=50 Global.save_best_model=True Global.eval_batch_step=[0,10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use latest instead of starting over\n",
        "#!python3 tools/train.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.checkpoints=./output/v3_en_mobile/latest Train.loader.batch_size_per_card=25 Eval.loader.batch_size_per_card=25 Global.use_gpu=False Global.epoch_num=50 Global.save_best_model=True Global.eval_batch_step=[0,100]"
      ],
      "metadata": {
        "id": "zooY54kjE3_y"
      },
      "id": "zooY54kjE3_y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3 tools/train.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.checkpoints=./output/v3_en_mobile/latest Train.loader.batch_size_per_card=25 Eval.loader.batch_size_per_card=25 Global.use_gpu=False Global.epoch_num=50 Global.save_best_model=True Global.eval_batch_step=[0,10]\n",
        "\n",
        "#train from 10 to 20 epochs\n",
        "#!python3 tools/train.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.checkpoints=./output/v3_en_mobile/latest Train.loader.batch_size_per_card=4 Eval.loader.batch_size_per_card=4 Global.use_gpu=False Global.epoch_num=20 Global.save_best_model=True Global.eval_batch_step=[17,2]"
      ],
      "metadata": {
        "id": "Pigu2-rXFgMB"
      },
      "id": "Pigu2-rXFgMB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-fUxJEnTJItp",
        "outputId": "b80f5f50-78ab-4389-eb52-94a28fa472a9"
      },
      "id": "-fUxJEnTJItp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/PaddleOCR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "img_path = 'train_data/val/'\n",
        "total = len(glob(img_path + '*.jpg'))\n",
        "total\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhD1q6t9I1Ga",
        "outputId": "54b1cb4d-b2b4-4dfe-ebeb-c886cf9c9b36"
      },
      "id": "nhD1q6t9I1Ga",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify your finetuned model path here!\n",
        "# A fine-tuned model called v3_en_mobile is available via Google cloud\n",
        "# Link: https://drive.google.com/drive/folders/1JS5SEloMik3JdPrjR6t9q2rbKesfdICN?usp=sharing\n",
        "# See README.md for more details.\n",
        "finetuned_path=\"./output/v3_en_mobile/best_accuracy\"\n",
        "\n",
        "subprocess.run([\"python3\", \"tools/infer_rec.py\",\n",
        "                \"-c\", \"configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml\",\n",
        "                \"-o\", \"Global.pretrained_model=\"+finetuned_path,\n",
        "                \"Global.infer_img=\"+img_path],\n",
        "                stdout=subprocess.DEVNULL,\n",
        "                stderr=subprocess.STDOUT)\n",
        "\n",
        "num_correct = 0\n",
        "incorrect_samples = []\n",
        "with open('output/rec/predicts_ppocrv3_en.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        line = line.split('\\t')\n",
        "        img_id = line[0].split('/')[-1]\n",
        "        pred = \"\".join(ch.upper() for ch in line[1] if ch.isalnum())\n",
        "\n",
        "        if true_labels[img_id] == pred:\n",
        "            num_correct += 1\n",
        "        else:\n",
        "            incorrect_samples.append((line[0], pred))\n",
        "\n",
        "print('The final accuracy is %.2f%%' % ((num_correct / total) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "pxN3mVrqJQ79",
        "outputId": "a4dd61cd-6992-4cbc-c505-c01dc1d2ff84"
      },
      "id": "pxN3mVrqJQ79",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'output/rec/predicts_ppocrv3_en.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-6b4f1c7ac24b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mincorrect_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/rec/predicts_ppocrv3_en.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/rec/predicts_ppocrv3_en.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randint\n",
        "print(len(incorrect_samples))\n",
        "index = randint(0, len(incorrect_samples)-1)\n",
        "index = 1\n",
        "actual = true_labels[incorrect_samples[index][0].split('/')[-1]]\n",
        "incorrect_samples[index][0]"
      ],
      "metadata": {
        "id": "rzaNLiJjJsKy"
      },
      "id": "rzaNLiJjJsKy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.axis('off')\n",
        "plt.title('Predicted: ' + incorrect_samples[index][1] + '\\n Actual: ' + actual)\n",
        "plt.imshow(plt.imread(incorrect_samples[index][0]))"
      ],
      "metadata": {
        "id": "6keJzMZNJvoV"
      },
      "id": "6keJzMZNJvoV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get model inference\n",
        "!python3 tools/export_model.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml \\\n",
        "-o Global.pretrained_model=./output/v3_en_mobile/best_accuracy \\\n",
        "Global.save_inference_dir=./inference/en_rec_custom\n"
      ],
      "metadata": {
        "id": "kKWo8TbRKGwj"
      },
      "id": "kKWo8TbRKGwj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download for local use\n",
        "!zip -r en_rec_custom.zip ./inference/en_rec_custom\n",
        "from google.colab import files\n",
        "files.download(\"en_rec_custom.zip\")\n",
        "\n",
        "#download checkpoint for local use\n",
        "!zip -r v3_en_mobile.zip ./output/v3_en_mobile/best_accuracy\n",
        "files.download(\"v3_en_mobile.zip\")\n"
      ],
      "metadata": {
        "id": "9dBNXnXtKwVo"
      },
      "id": "9dBNXnXtKwVo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "conda-root-py",
      "name": "pytorch-gpu.1-10.m90",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}